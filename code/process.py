import omegapy.omega_data as od
import numpy as np
import cubeio as cio
import os
from config import *

import glob
import xarray as xr
import omegapy
import math
from datetime import datetime, timedelta
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm
import traceback


class Process:
    cube_names = [] #for example ['0006_0']
    _cube_folders = [] #generated by import_cubes
    _temp_omega_data = None
    _base_bin_path = ''
    _base_py_path = ''
    _base_buffer_path = ''
    _dust_file_path = ''
    _dust_datasets = []
    _dust_files=[]

    _OUTPUT_DIR_No=''
    _OUTPUT_DIR_clean_cube=''
    _OUTPUT_DIR_atm=''
    _OUTPUT_DIR_rejected=''

    H = 11.0
    
    def __init__(self):
        self._base_bin_path = config.bin_path
        self._base_py_path = config.py_path
        self._base_buffer_path = config.buffer_path
        self._dust_file_path = config.dust_path
        self._OUTPUT_DIR_No = os.path.join(self._base_py_path,'processed')
        self._OUTPUT_DIR_clean_cube = os.path.join(self._base_py_path,'processed')
        self._OUTPUT_DIR_atm= os.path.join(self._base_py_path,'processed')
        self._OUTPUT_DIR_rejected = os.path.join(self._base_py_path,'processed', 'rejected')
        self._LOG_FILE = os.path.join(self._OUTPUT_DIR_No, "process_errors.log")
        os.makedirs(self._OUTPUT_DIR_No, exist_ok=True)
        os.makedirs(self._OUTPUT_DIR_clean_cube, exist_ok=True)
        os.makedirs(self._OUTPUT_DIR_atm, exist_ok=True)
        os.makedirs(self._OUTPUT_DIR_rejected, exist_ok=True)
        cio.log('Process', 'Initialization', 'INFO')

    def _utc_to_sol(self, utc_time):
        """
        参数:
        utc_time: datetime对象，表示UTC时间
        
        返回:
        字典，包含:
        - mars_year: 火星年
        - mars_sol: 火星日(从0开始)
        - fractional_sol: 火星日的小数部分(表示时间)
        """
        # 火星公元纪元开始时间 (Mars Year 1, Sol 0)
        mars_epoch = datetime(1955, 4, 11, 11, 4, 0)
        
        # 计算时间差(以天为单位)
        time_difference = utc_time - mars_epoch
        earth_days = time_difference.total_seconds() / 86400.0
        
        # 火星日与地球日的比率
        mars_sol_ratio = 1.02749125
        
        # 计算总火星日数
        total_mars_sols = earth_days / mars_sol_ratio
        
        # 火星年平均长度(火星日)
        mars_year_length = 668.5991
        
        # 计算火星年
        mars_year = total_mars_sols / mars_year_length
        mars_year_int = int(mars_year) + 1  # 火星年从1开始
        
        # 计算当前火星年中的火星日
        sol_in_year = (mars_year - int(mars_year)) * mars_year_length
        sol_int = int(sol_in_year)
        fractional_sol = sol_in_year - sol_int
        
        return {
            "mars_year": mars_year_int,
            "mars_sol": sol_int,
            "fractional_sol": fractional_sol
        }
    
    # ====== dust 插值 ======
    def _get_tau(self, sol, lat, lon, varname='cdodtot'):
        for i in range(0, len(self._dust_datasets)):
            if str(sol['mars_year']) in self._dust_files[i]:
                ds = self._dust_datasets[i]
                if sol['mars_sol'] >= ds.sol.min() and sol['mars_sol'] <= ds.sol.max():
                    try:
                        val = ds[varname].interp(sol=sol['mars_sol'], lat=lat, lon=lon)
                        return float(val)
                    except Exception as e:
                        cio.log('Process', 'Failed interpolation for sol=' + str(sol) + ', lat=' + str(lat) + ', lon=' + str(lon) + ': ' + str(e), 'ERROR')
        return None
    # ====== cube 路径导入 ======
    def import_cubes(self, cube_names:list):
        self.cube_names = cube_names
        cio.log('Process', 'Importing cubes...', 'DEBUG')
        # ====== 生成 cube 文件列表 ======
        for cube_name in cube_names:
            #第一种情况
            cube_folder = os.path.join(self._base_bin_path, f'ORB{cube_name}_DATA')
            if os.path.exists(cube_folder):
                self._cube_folders.append(cube_folder)
                continue
            #其他情况非标准先不考虑
            else:
                cio.log('Process', 'Cube not found: ' + cube_name, 'ERROR')
        return True


            
        return True
    # ====== cube 筛选 ======
    def _cube_passes_filters(self, cube, cube_name):
        try:
            # 获取平均几何条件
            inc = np.nanmean(cube.inci)
            emg = np.nanmean(cube.emer)
            alt = np.nanmean(cube.alt)
            lat = np.nanmean(cube.lat)
            lon = np.nanmean(cube.lon)
            
            # 获取UTC时间字符串
            utc_str = cube.utc.strftime("%Y-%m-%d %H:%M:%S")
            utc_time = datetime.strptime(utc_str, "%Y-%m-%d %H:%M:%S")
            sol = self._utc_to_sol(utc_time)

            if emg >= 15 or inc >= 75:
                cio.log('Process', 'Cube rejected: ' + cube_name + ' for first', 'INFO')
                self._add_rejected_record(cube_name=cube_name, reason="first")
                return False

            tau = self._get_tau(sol, lat, lon)
            if tau is None:
                cio.log('Process', 'Cube rejected: ' + cube_name + ' for notau', 'INFO')
                self._add_rejected_record(cube_name=cube_name, reason="notau")
                return False

            dust_crit = tau * np.exp(alt / self.H) * (1 + 1 / np.cos(np.radians(inc)))
            if dust_crit >= 2.0:
                cio.log('Process', 'Cube rejected: ' + cube_name + ' for second', 'INFO')
                self._add_rejected_record(cube_name=cube_name, reason="second")
                return False
            
            

            return True
        except Exception as e:
            cio.log('Process', 'cube_passes_filters error: ' + str(e), 'ERROR')
            return False
        
    # ====== 对于被剔除的文件记录在案，避免重复操作
    def _add_rejected_record(self, cube_name, reason):
        expected_rejected = os.path.join(self._OUTPUT_DIR_rejected, f"{cube_name}_rejected.txt")
        with open(expected_rejected, "w") as f:
                    f.write(f"Timestamp: {datetime.now()}\nReason: {reason}\n")
                    cio.log('Process', 'Added rejected record for ' + cube_name, 'INFO')
                    return expected_rejected
    # ====== 单个 cube 处理 ======
    def _process_cube(self, cube_name):
        try:
            # 从路径中提取观测名称
            # ====== 新增：检测是否已经校准/处理过 ======
            expected_out_no = os.path.join(self._OUTPUT_DIR_No, f"{cube_name}_processed.pkl")
            expected_out_clean = os.path.join(self._OUTPUT_DIR_clean_cube, f"{cube_name}_processed.pkl")
            expected_out_rejected = os.path.join(self._OUTPUT_DIR_rejected, f"{cube_name}_rejected.txt")
            
            if os.path.exists(expected_out_no):
                cio.log('Process', 'Skipping ' + cube_name + ': Already processed (found in OUTPUT_DIR_No)', 'INFO')
                return expected_out_no
            
            if os.path.exists(expected_out_clean):
                cio.log('Process', 'Skipping ' + cube_name + ': Already processed (found in OUTPUT_DIR_clean_cube)', 'INFO')
                return expected_out_clean
            
            if os.path.exists(expected_out_rejected):
                cio.log('Process', 'Skipping ' + cube_name + ': Already processed (found in OUTPUT_DIR_Rejected)', 'INFO')
                return expected_out_rejected
            


            # 加载OMEGA数据
            cubeio=cio.CubeIO(bin_path=self._base_bin_path, py_path=self._base_py_path, buffer_path=self._base_buffer_path)
            cube = cubeio.load(cube_name=cube_name, type='raw')
            
            if not self._cube_passes_filters(cube, cube_name):
                return None

            # 检查是否还有有效数据
            if np.all(np.isnan(cube.cube_rf)):
                cio.log('Process', f'All NAN in cube {cube_name}', 'ERROR')
                self._add_rejected_record(cube_name=cube_name, reason='all-nan')
                return None
                
            
            cube_corr = od.corr_therm_atm(cube, npool=1)

            cube_corr, key = self._clean_cube(cube_corr)

            if np.all(np.isnan(cube_corr.cube_rf)):
                cube_corr = od.corr_atm(cube)
                cube_corr, _ = self._clean_cube(cube_corr)
                if np.all(np.isnan(cube_corr.cube_rf)):
                    return None
                key = 2

            if key == 1:
                out_name = os.path.join(self._OUTPUT_DIR_clean_cube, f"{cube_name}_processed.pkl")
            elif key == 2:
                out_name = os.path.join(self._OUTPUT_DIR_atm, f"{cube_name}_processed.pkl")
            else:
                out_name = os.path.join(self._OUTPUT_DIR_No, f"{cube_name}_processed.pkl")
            
            

            # 使用omegapy的保存函数
            od.save_omega(cube_corr, savname = out_name)
            
            cio.log('Process', 'Processed and saved' + cube_name, 'INFO')
            
            return out_name
        except Exception as e:
            error_msg = f"Error processing {cube_name}: {str(e)}"
            cio.log('Process', error_msg, 'ERROR')
            traceback.print_exc()
            return None
    # ====== 清理 cube ======
    def _clean_cube(self, cube):
        try:
            # 创建一个掩码来标识有效像素
            valid_mask = np.ones(cube.cube_rf.shape[:2], dtype=bool)
            
            key = 0
            # 检查全零或全一的帧
            for i in range(cube.cube_rf.shape[0]):
                for j in range(cube.cube_rf.shape[1]):
                    spectrum = cube.cube_rf[i, j]
                    if np.all(spectrum == 0) or np.all(spectrum == 1):
                        valid_mask[i, j] = False
                        key = 1
            
            # 应用掩码
            for attr in ['cube_rf', 'cube_i', 'lat', 'lon', 'alt', 'inci', 'emer']:
                if hasattr(cube, attr):
                    data = getattr(cube, attr)
                    if data is not None:
                        # 对于3D数据（光谱立方体）
                        if len(data.shape) == 3:
                            for k in range(data.shape[2]):
                                data_slice = data[:, :, k]
                                data_slice[~valid_mask] = np.nan
                        # 对于2D数据（几何数据）
                        elif len(data.shape) == 2:
                            data[~valid_mask] = np.nan
                        setattr(cube, attr, data)

            return cube, key
        except Exception as e:
            cio.log('Clean', str(e), 'ERROR')
            return cube
    # ====== 主流程 ======
    def _process_all_parallel(self, max_workers=1):
        cio.log('Process', f"Found {len(self.cube_names)} OMEGA folders", 'INFO')

        #稍后需要与GUI同步修改
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(self._process_cube, qub): qub for qub in self.cube_names}

            for f in tqdm(as_completed(futures), total=len(futures), desc="Processing cubes"):
                result = f.result()
                if result:
                    cio.log('Process', 'Successfully processed: ' + result, 'INFO')
    def process_cubes(self, save=True, atm_corr=True, therm_corr=True):
        cio.log('Process', 'Processing cubes...', 'DEBUG')
        # ====== 预加载 dust 数据，并统一坐标 ======
        dust_paths = os.path.join(self._dust_file_path, '*.nc')
        self._dust_files = sorted(glob.glob(dust_paths))

        for f in self._dust_files:
            try:
                ds = xr.open_dataset(f)

                # 统一坐标名
                ds = ds.rename({'Time': 'sol', 'latitude': 'lat', 'longitude': 'lon'})
                self._dust_datasets.append(ds)

            except Exception as e:
                cio.log('Process', 'Failed to load ' + f + ': ' + str(e), 'ERROR')
        cio.log('Process', 'Loaded ' + str(len(self._dust_datasets)) + ' dust datasets.', 'INFO')
        self._process_all_parallel()
        
if __name__ == "__main__":
    process = Process()
    process.import_cubes(['0982_3'])
    process.process_cubes()
    cio.log('Process', 'Processing completed.', 'INFO')

    
    